 [DRAFT/WIP]


- poetry / pypi / docker build tests
- add tests
- add pydantic types for the api elements
d

This can be configured as a core configuration for underpinnings or on a run by run basis. Keep in mind that underpinnings normally runs in the context of a Kubernetes Pod but can also be used to test locally against two fixed repos.

# launch the api
Underpinnings runs in different ways, locally or on cluster. There is a swagger endpoint (knative or Fast API) which is used to receive jobs. You can also ask basic questions about the status of apps. The current version is very crude and just uses blob storage to store data.

## After the basic setup
You now have a CLI, a management cluster and a scaffolded cluster project that you can configure. The cluster manifests is simply a clone of cloud-stack which is for bootstrapping a standard cluster with observability stack.
One of the applications is the underpinnings workflow. The workflow pulls down a given ARepo branch from a CI/CD build. From there, we use underpin to create a target branch and template it into and then merge (github provider)

## other settings
- gc, s3 enabled, default bucket underpinnings
- 

TODO
- postgres instance for some data
- documentation
- installation tools
- dockerfile
 

 Refine
 - The processes and the git interactions should be studied a bit more. 

 poetry publish --build
 #https://stackoverflow.com/questions/53835198/integrating-python-poetry-with-docker

 https://dev.to/iamtekson/publish-package-to-pypi-and-release-new-version-using-github-actions-108k
 https://www.freecodecamp.org/news/docker-mount-volume-guide-how-to-mount-a-local-directory/